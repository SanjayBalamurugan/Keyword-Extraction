{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Exctraction\n",
    "\n",
    "Keyword extraction is defined as the task that automatically identifies a set of the terms that best describe the subject of document.\n",
    "\n",
    "\n",
    "### Automatic Keyword extraction algorithms used:\n",
    "\n",
    "- Rapid Automatic Keyword Extraction (RAKE). Python implementations\n",
    "- Gensim implementation of TextRank\n",
    "- Yet Another Keyword Extractor (YAKE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this kernel we will apply different keyword extraction approaches to the NIPS Paper dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-16T04:30:45.969972Z",
     "iopub.status.busy": "2022-06-16T04:30:45.969057Z",
     "iopub.status.idle": "2022-06-16T04:30:46.281401Z",
     "shell.execute_reply": "2022-06-16T04:30:46.280392Z",
     "shell.execute_reply.started": "2022-06-16T04:30:45.969903Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2022-06-16T04:30:47.507783Z",
     "iopub.status.busy": "2022-06-16T04:30:47.507475Z",
     "iopub.status.idle": "2022-06-16T04:30:50.878051Z",
     "shell.execute_reply": "2022-06-16T04:30:50.877288Z",
     "shell.execute_reply.started": "2022-06-16T04:30:47.507728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('/kaggle/input/nips-papers/papers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:31:00.809935Z",
     "iopub.status.busy": "2022-06-16T04:31:00.809229Z",
     "iopub.status.idle": "2022-06-16T04:31:00.835549Z",
     "shell.execute_reply": "2022-06-16T04:31:00.834560Z",
     "shell.execute_reply.started": "2022-06-16T04:31:00.809584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7241 entries, 0 to 7240\n",
      "Data columns (total 7 columns):\n",
      "id            7241 non-null int64\n",
      "year          7241 non-null int64\n",
      "title         7241 non-null object\n",
      "event_type    2422 non-null object\n",
      "pdf_name      7241 non-null object\n",
      "abstract      7241 non-null object\n",
      "paper_text    7241 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 396.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:31:02.088012Z",
     "iopub.status.busy": "2022-06-16T04:31:02.087653Z",
     "iopub.status.idle": "2022-06-16T04:31:02.101308Z",
     "shell.execute_reply": "2022-06-16T04:31:02.100320Z",
     "shell.execute_reply.started": "2022-06-16T04:31:02.087958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Abstract Missing\n",
      "1       Abstract Missing\n",
      "2       Abstract Missing\n",
      "3       Abstract Missing\n",
      "4       Abstract Missing\n",
      "              ...       \n",
      "7236    Abstract Missing\n",
      "7237    Abstract Missing\n",
      "7238    Abstract Missing\n",
      "7239    Abstract Missing\n",
      "7240    Abstract Missing\n",
      "Name: abstract, Length: 3317, dtype: object abstracts are missing\n"
     ]
    }
   ],
   "source": [
    "print(\"{} abstracts are missing\".format(df[df['abstract']=='Abstract Missing']['abstract']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:31:03.147753Z",
     "iopub.status.busy": "2022-06-16T04:31:03.147446Z",
     "iopub.status.idle": "2022-06-16T04:31:03.164677Z",
     "shell.execute_reply": "2022-06-16T04:31:03.163968Z",
     "shell.execute_reply.started": "2022-06-16T04:31:03.147696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TITLE:Density Propagation and Improved Bounds on the Partition Function'\n",
      "('ABSTRACT:Given a probabilistic graphical model, its density of states is a '\n",
      " 'function that, for any likelihood value, gives the number of configurations '\n",
      " 'with that probability. We introduce a novel message-passing algorithm called '\n",
      " 'Density Propagation (DP) for estimating this function. We show that DP is '\n",
      " 'exact for tree-structured graphical models and is, in general, a strict '\n",
      " 'generalization of both sum-product and max-product algorithms. Further, we '\n",
      " 'use density of states and tree decomposition to introduce a new family of '\n",
      " 'upper and lower bounds on the partition function. For any tree decompostion, '\n",
      " 'the new upper bound based on finer-grained density of state information is '\n",
      " 'provably at least as tight as previously known bounds based on convexity of '\n",
      " 'the log-partition function, and strictly stronger if a general condition '\n",
      " 'holds. We conclude with empirical evidence of improvement over convex '\n",
      " 'relaxations and mean-field based bounds.')\n",
      "('FULL TEXT:Density Propagation and\\n'\n",
      " 'Improved Bounds on the Partition Function?\\n'\n",
      " '\\n'\n",
      " 'Stefano Ermon, Carla P. Gomes\\n'\n",
      " 'Dept. of Computer Science\\n'\n",
      " 'Cornell University\\n'\n",
      " 'Ithaca NY 14853, U.S.A.\\n'\n",
      " '\\n'\n",
      " 'Ashish Sabharwal\\n'\n",
      " 'IBM Watson Research Ctr.\\n'\n",
      " 'Yorktown Heights\\n'\n",
      " 'NY 10598, U.S.A.\\n'\n",
      " '\\n'\n",
      " 'Bart Selman\\n'\n",
      " 'Dept. of Computer Science\\n'\n",
      " 'Cornell University\\n'\n",
      " 'Ithaca NY 14853, U.S.A.\\n'\n",
      " '\\n'\n",
      " 'Abstract\\n'\n",
      " 'Given a probabilistic graphical model, its density of states is a '\n",
      " 'distribution that,\\n'\n",
      " 'for any likelihood value, gives the number of configurations with that '\n",
      " 'probability. We introduce a novel message-passing algorithm called Density '\n",
      " 'Propagation\\n'\n",
      " '(DP) for estimating this distribution. We show that DP is exact for '\n",
      " 'tree-structured\\n'\n",
      " 'graphical models and is, in general, a strict generalization of both '\n",
      " 'sum-product and\\n'\n",
      " 'max-product algorithms. Further, we use density of states and tree '\n",
      " 'decomposition\\n'\n",
      " 'to introduce a new family of upper and lower bounds on the partition '\n",
      " 'function.\\n'\n",
      " 'For any tree decomposition, the new upper bound based on finer-grained '\n",
      " 'density\\n'\n",
      " 'of state information is provably at least as tight as previously known '\n",
      " 'bounds based\\n'\n",
      " 'on convexity of the log-partition function, and strictly stronger if a '\n",
      " 'general condition holds. We conclude with empirical evidence of improvement '\n",
      " 'over convex\\n'\n",
      " 'relaxations and mean-field based bounds.\\n'\n",
      " '\\n'\n",
      " '1\\n'\n",
      " '\\n'\n",
      " 'Introduction\\n'\n",
      " '\\n'\n",
      " 'Associated with any undirected graphical model [1] is the so-called density '\n",
      " 'of states, a term borrowed from statistical physics indicating a '\n",
      " 'distribution that, for any likelihood value, gives the\\n'\n",
      " 'number of configurations with that probability. The density of states plays '\n",
      " 'an important role in\\n'\n",
      " 'statistical physics because it provides a fine grained description of the '\n",
      " 'system, and can be used to\\n'\n",
      " 'efficiently compute many properties of interests, such as the partition '\n",
      " 'function and its parameterized\\n'\n",
      " 'version [2, 3]. It can be seen that computing the density of states is '\n",
      " 'computationally intractable in\\n'\n",
      " 'the worst case, since it subsumes a #-P complete problem (computing the '\n",
      " 'partition function) and an\\n'\n",
      " 'NP-hard one (')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "sample = 4114\n",
    "#2551\n",
    "#3113\n",
    "\n",
    "pprint.pprint(\"TITLE:{}\".format(df['title'][sample]))\n",
    "pprint.pprint(\"ABSTRACT:{}\".format(df['abstract'][sample]))\n",
    "pprint.pprint(\"FULL TEXT:{}\".format(df['paper_text'][sample][:2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:31:21.279119Z",
     "iopub.status.busy": "2022-06-16T04:31:21.278782Z",
     "iopub.status.idle": "2022-06-16T04:31:22.975154Z",
     "shell.execute_reply": "2022-06-16T04:31:22.974144Z",
     "shell.execute_reply.started": "2022-06-16T04:31:21.279069Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "##Creating a list of custom stopwords\n",
    "new_words = [\"fig\",\"figure\",\"image\",\"sample\",\"using\", \n",
    "             \"show\", \"result\", \"large\", \n",
    "             \"also\", \"one\", \"two\", \"three\", \n",
    "             \"four\", \"five\", \"seven\",\"eight\",\"nine\"]\n",
    "stop_words = list(stop_words.union(new_words))\n",
    "\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    ##Convert to list from string\n",
    "    text = text.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "\n",
    "    # remove words less than three letters\n",
    "    text = [word for word in text if len(word) >= 3]\n",
    "\n",
    "    # lemmatize\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    text = [lmtzr.lemmatize(word) for word in text]\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:31:24.337991Z",
     "iopub.status.busy": "2022-06-16T04:31:24.337663Z",
     "iopub.status.idle": "2022-06-16T04:34:55.887730Z",
     "shell.execute_reply": "2022-06-16T04:34:55.886915Z",
     "shell.execute_reply.started": "2022-06-16T04:31:24.337933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 975 ms, total: 3min 28s\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs = df['paper_text'].apply(lambda x:pre_process(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gensim implementation of TextRank summarization algorithm\n",
    "\n",
    "Gensim is a free Python library designed to automatically extract semantic topics from documents. The gensim implementation is based on the popular TextRank algorithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:35:08.614451Z",
     "iopub.status.busy": "2022-06-16T04:35:08.613857Z",
     "iopub.status.idle": "2022-06-16T04:35:09.045649Z",
     "shell.execute_reply": "2022-06-16T04:35:09.044612Z",
     "shell.execute_reply.started": "2022-06-16T04:35:08.614212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bound based',\n",
       " 'algorithms',\n",
       " 'partition',\n",
       " 'value',\n",
       " 'tree models',\n",
       " 'generalization',\n",
       " 'condition',\n",
       " 'densityof state',\n",
       " 'graphical',\n",
       " 'message',\n",
       " 'decompositionto',\n",
       " 'new',\n",
       " 'called',\n",
       " 'known',\n",
       " 'basedon',\n",
       " 'upper',\n",
       " 'strictly']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "text = \"Given a probabilistic graphical model, its density of states is a \" + \\\n",
    "\"distribution that,\" +\\\n",
    "\"for any likelihood value, gives the number of configurations with that \"+ \\\n",
    "\"probability. We introduce a novel message-passing algorithm called Density\" + \\\n",
    "\"Propagation\" + \\\n",
    "\"(DP) for estimating this distribution. We show that DP is exact for \"+ \\\n",
    "\"tree-structured\" + \\\n",
    "\"graphical models and is, in general, a strict generalization of both \"+ \\\n",
    "\"sum-product and\" +\\\n",
    "\"max-product algorithms. Further, we use density of states and tree \"+ \\\n",
    "\"decomposition\" + \\\n",
    "\"to introduce a new family of upper and lower bounds on the partition \"+ \\\n",
    "\"function.\"+ \\\n",
    "\"For any tree decomposition, the new upper bound based on finer-grained \"+ \\\n",
    "\"density\"+ \\\n",
    "\"of state information is provably at least as tight as previously known \" + \\\n",
    "\"bounds based\" + \\\n",
    "\"on convexity of the log-partition function, and strictly stronger if a \"+ \\\n",
    "\"general condition holds. We conclude with empirical evidence of improvement \"+ \\\n",
    "\"over convex\" + \\\n",
    "\"relaxations and mean-field based bounds.\"\n",
    "gensim.summarization.keywords(text, \n",
    "         ratio=0.5,               # use 50% of original text\n",
    "         words=None,              # Number of returned words\n",
    "         split=True,              # Whether split keywords\n",
    "         scores=False,            # Whether score of keyword\n",
    "         pos_filter=('NN', 'JJ'), # Part of speech (nouns, adjectives etc.) filters\n",
    "         lemmatize=True,         # If True - lemmatize words\n",
    "         deacc=True)              # If True - remove accentuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:35:10.824326Z",
     "iopub.status.busy": "2022-06-16T04:35:10.824008Z",
     "iopub.status.idle": "2022-06-16T04:35:10.835514Z",
     "shell.execute_reply": "2022-06-16T04:35:10.834667Z",
     "shell.execute_reply.started": "2022-06-16T04:35:10.824270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY:  ['Given a probabilistic graphical model, its density of states is a distribution that,for any likelihood value, gives the number of configurations with that probability.', 'We introduce a novel message-passing algorithm called DensityPropagation(DP) for estimating this distribution.']\n"
     ]
    }
   ],
   "source": [
    "print(\"SUMMARY: \", gensim.summarization.summarize(text,\n",
    "                                                  ratio = 0.5,\n",
    "                                                  split = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:35:14.097212Z",
     "iopub.status.busy": "2022-06-16T04:35:14.096903Z",
     "iopub.status.idle": "2022-06-16T04:35:14.104485Z",
     "shell.execute_reply": "2022-06-16T04:35:14.103669Z",
     "shell.execute_reply.started": "2022-06-16T04:35:14.097162Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_keywords_gensim(idx, docs):\n",
    "    \n",
    "    keywords=gensim.summarization.keywords(docs[idx], \n",
    "                                  ratio=None, \n",
    "                                  words=10,         \n",
    "                                  split=True,             \n",
    "                                  scores=False,           \n",
    "                                  pos_filter=None, \n",
    "                                  lemmatize=True,         \n",
    "                                  deacc=True)              \n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results_gensim(idx,keywords, df):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(df['title'][idx])\n",
    "    print(\"\\n=====Abstract=====\")\n",
    "    print(df['abstract'][idx])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:35:16.604058Z",
     "iopub.status.busy": "2022-06-16T04:35:16.603743Z",
     "iopub.status.idle": "2022-06-16T04:35:16.789763Z",
     "shell.execute_reply": "2022-06-16T04:35:16.789112Z",
     "shell.execute_reply.started": "2022-06-16T04:35:16.604008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Density Propagation and Improved Bounds on the Partition Function\n",
      "\n",
      "=====Abstract=====\n",
      "Given a probabilistic graphical model, its density of states is a function that, for any likelihood value, gives the number of configurations with that probability. We introduce a novel message-passing algorithm called Density Propagation (DP) for estimating this function. We show that DP is exact for tree-structured graphical models and is, in general, a strict generalization of both sum-product and max-product algorithms. Further, we use density of states and tree decomposition to introduce a new family of upper and lower bounds on the partition function. For any tree decompostion, the new upper bound based on finer-grained density of state information is provably at least as tight as previously known bounds based on convexity of the log-partition function, and strictly stronger if a general condition holds. We conclude with empirical evidence of improvement over convex relaxations and mean-field based bounds.\n",
      "\n",
      "===Keywords===\n",
      "bounded\n",
      "algorithm\n",
      "model\n",
      "energy\n",
      "tree\n",
      "density\n",
      "message\n",
      "function\n",
      "computation\n",
      "matched\n"
     ]
    }
   ],
   "source": [
    "idx=4114\n",
    "keywords=get_keywords_gensim(idx, docs)\n",
    "print_results_gensim(idx,keywords, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapid Automatic Keyword Extraction algorithm (RAKE)\n",
    "\n",
    "\n",
    "### Setup using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:35:32.304609Z",
     "iopub.status.busy": "2022-06-16T04:35:32.304303Z",
     "iopub.status.idle": "2022-06-16T04:35:42.840868Z",
     "shell.execute_reply": "2022-06-16T04:35:42.840041Z",
     "shell.execute_reply.started": "2022-06-16T04:35:32.304558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rake-nltk\r\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/e5/18876d587142df57b1c70ef752da34664bb7dd383710ccf3ccaefba2aa0c/rake_nltk-1.0.6-py3-none-any.whl\r\n",
      "Collecting nltk<4.0.0,>=3.6.2 (from rake-nltk)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/ea/84c7247f5c96c5a1b619fe822fb44052081ccfbe487a49d4c888306adec7/nltk-3.6.7-py3-none-any.whl (1.5MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 592kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (0.13.2)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (7.0)\r\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.6.2->rake-nltk)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/13/5fb3cb045a40baa76e32e1403b4f356c8f60db706ad59f1ac8ec549efbaa/regex-2022.6.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (671kB)\r\n",
      "\u001b[K     |████████████████████████████████| 675kB 9.7MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.36.1)\r\n",
      "\u001b[31mERROR: allennlp 0.9.0 requires flaky, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: allennlp 0.9.0 requires responses>=0.7, which is not installed.\u001b[0m\r\n",
      "\u001b[31mERROR: preprocessing 0.1.13 has requirement nltk==3.2.4, but you'll have nltk 3.6.7 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: regex, nltk, rake-nltk\r\n",
      "  Found existing installation: regex 2019.8.19\r\n",
      "    Uninstalling regex-2019.8.19:\r\n",
      "      Successfully uninstalled regex-2019.8.19\r\n",
      "  Found existing installation: nltk 3.2.4\r\n",
      "    Uninstalling nltk-3.2.4:\r\n",
      "      Successfully uninstalled nltk-3.2.4\r\n",
      "Successfully installed nltk-3.6.7 rake-nltk-1.0.6 regex-2022.6.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install rake-nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:35:42.843660Z",
     "iopub.status.busy": "2022-06-16T04:35:42.843299Z",
     "iopub.status.idle": "2022-06-16T04:35:42.851952Z",
     "shell.execute_reply": "2022-06-16T04:35:42.850783Z",
     "shell.execute_reply.started": "2022-06-16T04:35:42.843607Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Given a probabilistic graphical model, its density of states is a \" + \\\n",
    "\"distribution that,\" +\\\n",
    "\"for any likelihood value, gives the number of configurations with that \"+ \\\n",
    "\"probability. We introduce a novel message-passing algorithm called Density\" + \\\n",
    "\"Propagation\" + \\\n",
    "\"(DP) for estimating this distribution. We show that DP is exact for \"+ \\\n",
    "\"tree-structured\" + \\\n",
    "\"graphical models and is, in general, a strict generalization of both \"+ \\\n",
    "\"sum-product and\" +\\\n",
    "\"max-product algorithms. Further, we use density of states and tree \"+ \\\n",
    "\"decomposition\" + \\\n",
    "\"to introduce a new family of upper and lower bounds on the partition \"+ \\\n",
    "\"function.\"+ \\\n",
    "\"For any tree decomposition, the new upper bound based on finer-grained \"+ \\\n",
    "\"density\"+ \\\n",
    "\"of state information is provably at least as tight as previously known \" + \\\n",
    "\"bounds based\" + \\\n",
    "\"on convexity of the log-partition function, and strictly stronger if a \"+ \\\n",
    "\"general condition holds. We conclude with empirical evidence of improvement \"+ \\\n",
    "\"over convex\" + \\\n",
    "\"relaxations and mean-field based bounds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:35:44.683781Z",
     "iopub.status.busy": "2022-06-16T04:35:44.683443Z",
     "iopub.status.idle": "2022-06-16T04:35:44.710990Z",
     "shell.execute_reply": "2022-06-16T04:35:44.710267Z",
     "shell.execute_reply.started": "2022-06-16T04:35:44.683718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23.333333333333336, 'previously known bounds basedon convexity'),\n",
       " (16.0, 'passing algorithm called densitypropagation'),\n",
       " (16.0, 'grained densityof state information'),\n",
       " (13.0, 'new upper bound based'),\n",
       " (9.833333333333334, 'field based bounds'),\n",
       " (9.0, 'probabilistic graphical model'),\n",
       " (8.0, 'general condition holds'),\n",
       " (7.0, 'tree decompositionto introduce'),\n",
       " (5.333333333333334, 'lower bounds'),\n",
       " (5.0, 'new family')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "r = Rake()\n",
    "r.extract_keywords_from_text(text)\n",
    "r.get_ranked_phrases_with_scores()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:36:45.234972Z",
     "iopub.status.busy": "2022-06-16T04:36:45.234635Z",
     "iopub.status.idle": "2022-06-16T04:36:45.242362Z",
     "shell.execute_reply": "2022-06-16T04:36:45.241599Z",
     "shell.execute_reply.started": "2022-06-16T04:36:45.234921Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_keywords_rake(idx, docs, n=10):\n",
    "    # Uses stopwords for english from NLTK, and all puntuation characters by default\n",
    "    r = Rake()\n",
    "    \n",
    "    # Extraction given the text.\n",
    "    r.extract_keywords_from_text(docs[idx][1000:2000])\n",
    "    \n",
    "    # To get keyword phrases ranked highest to lowest.\n",
    "    keywords = r.get_ranked_phrases()[0:n]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results(idx,keywords, df):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(df['title'][idx])\n",
    "    print(\"\\n=====Abstract=====\")\n",
    "    print(df['abstract'][idx])\n",
    "    print(\"\\n===Keywords===\")\n",
    "    for k in keywords:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:36:47.123943Z",
     "iopub.status.busy": "2022-06-16T04:36:47.123609Z",
     "iopub.status.idle": "2022-06-16T04:36:47.134558Z",
     "shell.execute_reply": "2022-06-16T04:36:47.133471Z",
     "shell.execute_reply.started": "2022-06-16T04:36:47.123891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Density Propagation and Improved Bounds on the Partition Function\n",
      "\n",
      "=====Abstract=====\n",
      "Given a probabilistic graphical model, its density of states is a function that, for any likelihood value, gives the number of configurations with that probability. We introduce a novel message-passing algorithm called Density Propagation (DP) for estimating this function. We show that DP is exact for tree-structured graphical models and is, in general, a strict generalization of both sum-product and max-product algorithms. Further, we use density of states and tree decomposition to introduce a new family of upper and lower bounds on the partition function. For any tree decompostion, the new upper bound based on finer-grained density of state information is provably at least as tight as previously known bounds based on convexity of the log-partition function, and strictly stronger if a general condition holds. We conclude with empirical evidence of improvement over convex relaxations and mean-field based bounds.\n",
      "\n",
      "===Keywords===\n",
      "efficiently compute many properties\n",
      "#- p complete problem\n",
      "previously known bounds based\n",
      "field based bounds\n",
      "undirected graphical model\n",
      "general condition holds\n",
      "fine grained description\n",
      "statistical physics indicating\n",
      "1 introduction associated\n",
      "statistical physics\n"
     ]
    }
   ],
   "source": [
    "idx=4114\n",
    "keywords = get_keywords_rake(idx, df['paper_text'], n=10)\n",
    "print_results(idx, keywords, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yet Another Keyword Extractor (Yake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:37:10.554524Z",
     "iopub.status.busy": "2022-06-16T04:37:10.554202Z",
     "iopub.status.idle": "2022-06-16T04:37:25.290002Z",
     "shell.execute_reply": "2022-06-16T04:37:25.289148Z",
     "shell.execute_reply.started": "2022-06-16T04:37:10.554471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/LIAAD/yake\r\n",
      "  Cloning https://github.com/LIAAD/yake to /tmp/pip-req-build-j7xxrw7c\r\n",
      "  Running command git clone -q https://github.com/LIAAD/yake /tmp/pip-req-build-j7xxrw7c\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages/tabulate-0.8.5-py3.6.egg (from yake==0.4.8) (0.8.5)\r\n",
      "Requirement already satisfied: click>=6.0 in /opt/conda/lib/python3.6/site-packages (from yake==0.4.8) (7.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from yake==0.4.8) (1.16.4)\r\n",
      "Collecting segtok (from yake==0.4.8)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/60/d384dbae5d4756e33f1750fa3472303de2c827011907a64e213e114d0556/segtok-1.5.11-py3-none-any.whl\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.6/site-packages (from yake==0.4.8) (2.3)\r\n",
      "Collecting jellyfish (from yake==0.4.8)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/18/cd485f3661c8e8c0ab864c2e54033371dcc1f7e75767318a4044b2808ed4/jellyfish-0.9.0.tar.gz (132kB)\r\n",
      "\u001b[K     |████████████████████████████████| 133kB 849kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from segtok->yake==0.4.8) (2022.6.2)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx->yake==0.4.8) (4.4.0)\r\n",
      "Building wheels for collected packages: yake, jellyfish\r\n",
      "  Building wheel for yake (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for yake: filename=yake-0.4.8-py2.py3-none-any.whl size=62573 sha256=47b8d5e48fc452c9cb25af7a3722d6954996360e82199e5015d2fd098d576486\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wfkgpgz1/wheels/be/35/27/e4ebd54b78c1806ed8b0271ce247fcd91e2bedde35889fbc9b\r\n",
      "  Building wheel for jellyfish (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp36-cp36m-linux_x86_64.whl size=83653 sha256=1e3e77ce7842a9652111c0d66eda5b5302bb39435fb054d9e25a476494a7a721\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/3c/47/6bc8def8183057f4912eff840c4d43e5892c566165b30ab020\r\n",
      "Successfully built yake jellyfish\r\n",
      "Installing collected packages: segtok, jellyfish, yake\r\n",
      "Successfully installed jellyfish-0.9.0 segtok-1.5.11 yake-0.4.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/LIAAD/yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-16T04:37:25.294426Z",
     "iopub.status.busy": "2022-06-16T04:37:25.294121Z",
     "iopub.status.idle": "2022-06-16T04:37:25.892824Z",
     "shell.execute_reply": "2022-06-16T04:37:25.891936Z",
     "shell.execute_reply.started": "2022-06-16T04:37:25.294375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Title=====\n",
      "Density Propagation and Improved Bounds on the Partition Function\n",
      "\n",
      "=====Abstract=====\n",
      "Given a probabilistic graphical model, its density of states is a function that, for any likelihood value, gives the number of configurations with that probability. We introduce a novel message-passing algorithm called Density Propagation (DP) for estimating this function. We show that DP is exact for tree-structured graphical models and is, in general, a strict generalization of both sum-product and max-product algorithms. Further, we use density of states and tree decomposition to introduce a new family of upper and lower bounds on the partition function. For any tree decompostion, the new upper bound based on finer-grained density of state information is provably at least as tight as previously known bounds based on convexity of the log-partition function, and strictly stronger if a general condition holds. We conclude with empirical evidence of improvement over convex relaxations and mean-field based bounds.\n",
      "\n",
      "===Keywords===\n",
      "('probabilistic graphical model', 0.012019195204905426)\n",
      "('probabilistic graphical', 0.030696201965851447)\n",
      "('that,for any likelihood', 0.030696201965851447)\n",
      "('number of configurations', 0.030696201965851447)\n",
      "('distribution that,for', 0.04921693805270738)\n",
      "('graphical model', 0.06449680093636577)\n",
      "('algorithm called DensityPropagation', 0.09429058269779998)\n",
      "('message-passing algorithm called', 0.11353063825897151)\n",
      "('density of states', 0.12094069657154304)\n",
      "('distribution', 0.1359071541772584)\n"
     ]
    }
   ],
   "source": [
    "import yake\n",
    "\n",
    "def get_keywords_yake(idx, docs):\n",
    "    y = yake.KeywordExtractor(lan='en',          # language\n",
    "                             n = 3,              # n-gram size\n",
    "                             dedupLim = 0.9,     # deduplicationthresold\n",
    "                             dedupFunc = 'seqm', #  deduplication algorithm\n",
    "                             windowsSize = 1,\n",
    "                             top = 10,           # number of keys\n",
    "                             features=None)           \n",
    "    \n",
    "    keywords = y.extract_keywords(text)\n",
    "    return keywords\n",
    "\n",
    "idx= 4114\n",
    "keywords = get_keywords_yake(idx, docs[idx])\n",
    "print_results(idx, keywords, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
